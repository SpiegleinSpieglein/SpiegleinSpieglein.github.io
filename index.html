<!DOCTYPE html>
<html lang="de">

<head>
    <title>SpiegleinSpieglein</title>
    <link rel="icon" href="logo_spieglein.ico" />

    <meta http-equiv="X-UA-Compatible" content="IE=edge" ; charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta property="og:title" content="SpiegleinSpieglein" />
    <meta property="og:description" content="SpiegleinSpieglein" />
    <meta property="og:site_name" content="SpiegleinSpieglein.github.io" />
    <meta property="og:image" content="logo_spieglein.jpg" />

    <!-- Eigenes CSS -->
    <link href="style.css" rel="stylesheet">
</head>

<body>
    <div class="grid">
        <div class="title">
            <img src="logo_spieglein.jpg" />
        </div>
        <div class="text1">
            <p>Durch die Anwendung schlüpft der Nutzer ganz einfach in verschiedene historische Kleider, die so interaktiv erlebbar sind. Der Nutzer kann sich auf einem großen Bildschirm, welcher als Spiegel dient, betrachten. Ein Kleid wird an seine Position und somit auf sein Körper projeziert und macht alle Bewegungen mit. Außerdem kann mit Gesten zwischen verschiedenen Kleidern gewechselt werden.
            </p>
            <a class="button" href="https://github.com/SpiegleinSpieglein/SpiegleinSpieglein" target="_blank">Show Code</a>
        </div>
        <div class="text2">
            <p>"Spieglein, Spieglein" verwendet 3D-Scans der Kleider des Historischen Museums Frankfurt. Diese wurden von dem Projekt "Das bewegte Kleid" photogrammetrisch aufgenommen und uns zur Verfügung gestellt. Die originalen Kleider aus dem Projekt "Kleider in Bewegung" des Museums können verständlicherweise von Besuchern nicht getragen werden. Damit sind sie leider nicht in Bewegung, sondern nur hinter Glasscheiben betrachtbar. Das ändern wir mit unserer Anwendung: Wir haben die Scans der Kleider genutzt, um sie digitalen Skeletten überzuziehen. Mit Hilfe einer "XBox 360 Kinect" nehmen wir ein Tiefenbild der Umgebung auf. Damit können wir Position und Haltung des Nutzers bestimmen und so live das digitale 3D-Kleid mit dem realen Kamerabild des Nutzers verbinden. So entsteht der Eindruck, als trüge man das Kleid am eigenen Körper.
            Die Bewegungsdaten des Nutzers nutzen wir zudem auch, um Gesten zuerkennen und so zuentscheiden, welches Kleid gerade getragen wird.
            </p>
        </div>
        <div class="footer">
            <p><a href="https://codingdavinci.de/events/rheinmain/" target="_blank">Coding da Vinci Rhein-Main 2018</a></p>
        </div>
    </div>
</body>

</html>
